{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO8WLqj1TW3v0YwZnkBkH7e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/laura-turnbull-lloyd/STDH_teaching/blob/main/STDH2324_Lecture6_recurenceintervals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 1: Recurrence intervals\n",
        "Have a go at calculating open and closed recurrence intervals for the four earthquakes in the Personius paper. Recall that:\n",
        "\n",
        "> $ Open RI = \\frac{oldest age to present}{number of events}$\n",
        "\n",
        "> $ Closed RI = \\frac{oldest age - youngest age}{number of intervals}$\n",
        "\n",
        "We can directly enter the earthquake dates:"
      ],
      "metadata": {
        "id": "O_HBTwS7Cgu1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WE4u1R9wCDJL"
      },
      "outputs": [],
      "source": [
        "# read in the dates of the four earthquakes from the Personius paper\n",
        "dateBP = [5610, 4510, 3490, 2430]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have our earthquake dates, we can calculate the open recurrence interval."
      ],
      "metadata": {
        "id": "47JjdpcLdb9U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "openRI = max(dateBP)/(len(dateBP)) # here we use len(dateBP) to give us the length of the dataset (i.e. how many events there are)\n",
        "\n",
        "print(openRI)\n"
      ],
      "metadata": {
        "id": "L8sJDmVJddeM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Now, calculate the closed recurrence interval and print out the result. ***"
      ],
      "metadata": {
        "id": "kwR0BLyEdtux"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# You can enter your code here."
      ],
      "metadata": {
        "id": "CO_wA-ztd3cs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your answer should be 1060"
      ],
      "metadata": {
        "id": "J2OadRIxfiJY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Exercise 2: Bringing magnitude into the equation\n",
        "\n",
        "Let's generalise and say that we know the rate of an event that we might expect of a given size per year.\n",
        "\n",
        "Over time, if events continue to occur at that same unchanged rate, that we can express that probability (the exceedance probability) using this equation:\n",
        "> $ p_{n,1} = {1-(1-p)^n}$\n",
        "\n",
        "Let's have a go at calculating the exceedance probability for an event with an expected rate of 0.1 per year, over 5 years.\n"
      ],
      "metadata": {
        "id": "3jJPMeg2vo5J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# m is the expected number of occurrences of an event of at least a given size per year\n",
        "m = 0.1\n",
        "\n",
        "# T is the expected recurrence time for events of at elast that size\n",
        "T = 1/m\n",
        "\n",
        "p = 1/T\n",
        "\n",
        "# n is the number of years we're interested in for the sake of these calculations\n",
        "n = 5"
      ],
      "metadata": {
        "id": "XFQ5ZONNvuvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Have a go at entering the equation to calculate the probability of exceedance over 50 years below and print out your result (recall that in the first week we covered how to raise a number to a power).***"
      ],
      "metadata": {
        "id": "eNbq1BFxykiR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate the exceedance probability here:\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "foYb7IRjv3aK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you did this correctly, you should get 0.410\n",
        "\n",
        "To summarise, what you've done here is calculate the exceedance probability of at least one event of a specific size occurring, and this depends on the rate at which that event occurs, and the time period of interest.\n",
        "\n",
        "***Now, have a go at calculating the probabiltiy of no events occurring over the same time period.***"
      ],
      "metadata": {
        "id": "Qx7mq2Esy8nL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate the probability of no events occurring over the same time period\n"
      ],
      "metadata": {
        "id": "jbQ4K3XYyR6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you increase the number of years in question, the probability (i.e. the likelihood of an event happning) will get closer to 1. And conversely, the probability of no event happening will get closer to 0 with a longer time span.\n",
        "\n",
        "***Now, have a go at answering the following:***\n",
        "\n",
        "***What is the exceedance probability of a 100-yr event occurring over a 30 yr period?***\n",
        "\n",
        "***What is the probability of non-occurrence?***\n"
      ],
      "metadata": {
        "id": "l0iEEAZ111rx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 3"
      ],
      "metadata": {
        "id": "wivavNwO2leo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's have a go at calculating recurrence intervals for annual maximum river flow in the UK. We can download the max river flow data for any gauge in the UK from the NRFA (https://nrfa.ceh.ac.uk/data/).\n",
        "\n",
        "You can access the data we're using here: https://nrfa.ceh.ac.uk/data/station/peakflow/24001.\n"
      ],
      "metadata": {
        "id": "r2m108S53i8g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import modules\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "toU842w40iFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To open the data:\n"
      ],
      "metadata": {
        "id": "qr3Sq5EG6AgS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Filename = 'Wear_at_Sunderland.csv' # specifying the name of the file to be read in\n",
        "flowmax = pd.read_csv(Filename)"
      ],
      "metadata": {
        "id": "FE-47y_E6CNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we've go our data, let's have a quick look at it:"
      ],
      "metadata": {
        "id": "9DxOGOLe2vbx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "flowmax"
      ],
      "metadata": {
        "id": "tRLg3NrJ1sUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You'll see that the data already come ranked, form largerst to smallest. This is handy, but data don't always come this well prepared. So let's go through manually ranking the data, and check that we get the same results!\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2VdlXWpR24hq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rank_flow = sorted(list(flowmax.Flow_m3s), reverse=True)"
      ],
      "metadata": {
        "id": "zWIz8xjO4y0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rank_flow"
      ],
      "metadata": {
        "id": "ToxT_Q9T436C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "number_years = len(flowmax)"
      ],
      "metadata": {
        "id": "WMdua8vE8HNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "number_years"
      ],
      "metadata": {
        "id": "njoTB9Bf-rTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rank_data = list(range(1,number_years+1,1))"
      ],
      "metadata": {
        "id": "7FL1zG-g8SMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rank_df = pd.DataFrame({'rank_flow' :rank_flow, 'rank_data':rank_data})\n"
      ],
      "metadata": {
        "id": "NimXureP5Lpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's view our new dataframe containing earthquake magnitudes, sorted in descending order, and their rank."
      ],
      "metadata": {
        "id": "3DyHTt90Bx9-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rank_df"
      ],
      "metadata": {
        "id": "yU5SnH679fVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we can finally calculate the exceedace probability and add this to the dataframe in a new column called 'pe'\n"
      ],
      "metadata": {
        "id": "itcLrT4fB68D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rank_df['pe'] = rank_df.rank_data/(number_years+1)"
      ],
      "metadata": {
        "id": "U2UR0VK5CAkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Can you now calculate the Weibull return time and add it to the dataframe?***"
      ],
      "metadata": {
        "id": "hGMGivpQFl-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Add the equation for the Weibull return time here in a new column called 'WRT':\n",
        "\n"
      ],
      "metadata": {
        "id": "R9xrY_A6Fqfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's plot out the results:"
      ],
      "metadata": {
        "id": "IY_AaZN1F7xp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.ticker import ScalarFormatter\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(rank_df.pe,rank_df.rank_flow, 'o', color='red')\n",
        "plt.ylabel(\"Annual maximum flow\")\n",
        "plt.xlabel(\"Exceedance probability\")\n",
        "plt.tight_layout() # makes the plot look nicer!\n",
        "plt.xlim(1,0.01) # to have probabilities going form largest to smallest\n",
        "ax.set_xscale('log')\n",
        "ax.set_yscale('log')\n",
        "for axis in [ax.xaxis, ax.yaxis]:\n",
        "    axis.set_major_formatter(ScalarFormatter())\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(rank_df.WRT, rank_df.rank_flow, 'o', color='red')\n",
        "plt.xlabel(\"Return period\")\n",
        "plt.ylabel(\"Annual maximum flow\")\n",
        "plt.tight_layout() # makes the plot look nicer!\n",
        "ax.set_xscale('log')\n",
        "ax.set_yscale('log')\n",
        "for axis in [ax.xaxis, ax.yaxis]:\n",
        "    axis.set_major_formatter(ScalarFormatter())"
      ],
      "metadata": {
        "id": "vksbXz0kGL6S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}